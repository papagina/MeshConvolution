[Record]
read_weight_path: 
write_weight_folder: ../../train/0422_graphAE_dfaust/weight_30/
write_tmp_folder: ../../train/0422_graphAE_dfaust/tmp_30/
logdir: ../../train/0422_graphAE_dfaust/log_30/



[Params] 
lr: 0.0001

batch: 16

w_pose: 1
w_laplace: 0 

augment_data: 0

weight_decay: 0.00000
lr_decay: 0.99
lr_decay_epoch_step: 1


start_epoch: 0
epoch: 201
evaluate_epoch: 2

perpoint_bias: 0


template_ply_fn: ../../data/DFAUST/template.ply


point_num: 6890

pcs_train: ../../data/DFAUST/train.npy

pcs_evaluate: ../../data/DFAUST/eval.npy

pcs_test: ../../data/DFAUST/test.npy


connection_folder:  ../../train/0422_graphAE_dfaust/ConnectionMatrices/

initial_connection_fn:../../train/0422_graphAE_dfaust/ConnectionMatrices/_pool0.npy


connection_layer_lst: ["pool0", "pool1", "pool2","pool3", "pool4", "pool5", "pool6", "pool7", "unpool7","unpool6", "unpool5","unpool4","unpool3","unpool2","unpool1", "unpool0"]

## pool and unpool layer's output channel number should be the same as the previous layer
channel_lst:          [ 32, 32,  64, 64, 128, 128, 9, 9, 9, 128, 128,64, 64,32, 32,3]

weight_num_lst:       [9,0, 9,0, 9,0, 9,0,   0,9, 0,9,0,9,0,9]

## 0 for conv only, 1 for (un)pool and residual layer, 0.X for residual block: (1-0.X)*conv+0.X*res 
residual_rate_lst:    [0,1,  0,1,  0,1,  0,1,   1,0,  1,0,  1,0,  1,0]






